{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorul 5 SVM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfkrECccC6na",
        "colab_type": "code",
        "outputId": "6ec8bfd4-494a-40a5-e023-4b9ef26f1d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget https://fmi-unibuc-ia.github.io/ia/Data/data_lab5.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 07:45:18--  https://fmi-unibuc-ia.github.io/ia/Data/data_lab5.zip\n",
            "Resolving fmi-unibuc-ia.github.io (fmi-unibuc-ia.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to fmi-unibuc-ia.github.io (fmi-unibuc-ia.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503740 (492K) [application/zip]\n",
            "Saving to: ‘data_lab5.zip.1’\n",
            "\n",
            "\rdata_lab5.zip.1       0%[                    ]       0  --.-KB/s               \rdata_lab5.zip.1     100%[===================>] 491.93K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-04-30 07:45:18 (7.91 MB/s) - ‘data_lab5.zip.1’ saved [503740/503740]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0-Nm-xYDANn",
        "colab_type": "code",
        "outputId": "1d285f9d-b1b8-41e7-d7e9-3487bd558deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!unzip data_lab5.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data_lab5.zip\n",
            "replace data/test_labels.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/test_labels.npy    \n",
            "replace data/test_sentences.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace data/test_sentences.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/test_sentences.npy  \n",
            "  inflating: data/training_labels.npy  \n",
            "  inflating: data/training_sentences.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svDb0LQADHuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = np.load('data/training_sentences.npy', allow_pickle=True)\n",
        "train_labels = np.load('data/training_labels.npy')\n",
        "\n",
        "test_data = np.load('data/test_sentences.npy', allow_pickle=True)\n",
        "test_labels = np.load('data/test_labels.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmONfHc-DBIl",
        "colab_type": "code",
        "outputId": "2b2ce3c2-8473-48c7-a3af-d0f1cf8547bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def normalize_data(train_data, test_data, norm_type=None):\n",
        "    if norm_type is None:\n",
        "        return train_data, test_data\n",
        "    if norm_type == 'standard':\n",
        "        scaler = preprocessing.StandardScaler()\n",
        "        scaler.fit(train_data)\n",
        "        return scaler.transform(train_data), scaler.transform(test_data)\n",
        "    if norm_type == 'min_max':\n",
        "        return (preprocessing.minmax_scale(train_data, axis=-1),\n",
        "                preprocessing.minmax_scale(test_data, axis=-1))\n",
        "    if norm_type == 'l1':\n",
        "        return (preprocessing.normalize(train_data, norm='l1'),\n",
        "                preprocessing.normalize(test_data, norm='l1'))\n",
        "    if norm_type == 'l2':\n",
        "        return (preprocessing.normalize(train_data, norm='l2'),\n",
        "                preprocessing.normalize(test_data, norm='l2'))\n",
        "\n",
        "np.random.seed(7)\n",
        "normalize_data(np.random.randn(1, 7), np.random.randn(1, 5), norm_type='l2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 8.59950904e-01, -2.37016960e-01,  1.66952383e-02,\n",
              "          2.07298827e-01, -4.01316034e-01,  1.05073308e-03,\n",
              "         -4.52929004e-04]]),\n",
              " array([[-0.7930376 ,  0.45992471,  0.27139187, -0.28265904, -0.07753025]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkJoGyNcDd7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BagOfWords:\n",
        "    def __init__(self):\n",
        "        self.vocabulary = dict()\n",
        "        self.known_words = ['UNK']\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.known_words)\n",
        "\n",
        "    def add_to_vocabulary(self, word):\n",
        "        if word in self.vocabulary.keys():\n",
        "            return\n",
        "\n",
        "        self.vocabulary[word] = len(self.known_words)\n",
        "        self.known_words.append(word)\n",
        "\n",
        "    def build_vocabulary(self, data):\n",
        "        for message in data:\n",
        "            for word in message:\n",
        "                self.add_to_vocabulary(word)\n",
        "\n",
        "    def get_features(self, data):\n",
        "        features = []\n",
        "        for message in data:\n",
        "            words = np.zeros(self.vocab_size)\n",
        "            for word in message:\n",
        "                index = self.vocabulary.get(word, 0)\n",
        "                words[index] += 1\n",
        "            features.append(words)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "bow = BagOfWords()\n",
        "bow.build_vocabulary(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIlfY8EVHuV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = bow.get_features(train_data)\n",
        "test_features = bow.get_features(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2CmHKlTKCVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = normalize_data(train_features, test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRFm_8eJmBJ",
        "colab_type": "code",
        "outputId": "a3a776ab-f58e-4205-c179-b1397755e537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(C=1.0, kernel='linear')\n",
        "clf.fit(X_train, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0AgM4KxKARz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsCJQ8wJKQqx",
        "colab_type": "code",
        "outputId": "63bc503e-c81d-46a9-b866-eb28d7953aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_preds)\n",
        "f1 = f1_score(test_labels, y_preds)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 score:\", f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9847826086956522\n",
            "F1 score: 0.9423868312757202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEUr51yKrCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vectors = []\n",
        "\n",
        "for word in bow.known_words[1:]:\n",
        "    word_vector = np.zeros(bow.vocab_size)\n",
        "    word_vector[bow.vocabulary[word]] = 1\n",
        "    word_vectors.append(word_vector)\n",
        "\n",
        "word_vectors = np.array(word_vectors)\n",
        "\n",
        "values = clf.decision_function(word_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiKeOGmZNbq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_indexes = np.argsort(values)\n",
        "\n",
        "top_positive = sorted_indexes[:10]\n",
        "top_negative = sorted_indexes[-10:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkaa3PSTOCNA",
        "colab_type": "code",
        "outputId": "7104aa26-e76d-4c44-f34b-cb24bb87bfda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(\"Top 10 spam:\")\n",
        "for word_index in top_positive:\n",
        "    print(bow.known_words[word_index], end=' ')\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Top 10 non-spam:\")\n",
        "for word_index in top_negative:\n",
        "    print(bow.known_words[word_index], end=' ')\n",
        "\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 spam:\n",
            "wish contact httptms RingtoneFrom 85233 dado weekends TONESReply Ref9280114 ringtoneking \n",
            "Top 10 non-spam:\n",
            "usc call message ryans thing one bread fringe legs Bergkamp \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpgnF7erOecb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}